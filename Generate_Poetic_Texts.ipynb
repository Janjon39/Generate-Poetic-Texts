{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tiNnurX2Kdpo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM , Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUo7Dyo2MMd6",
        "outputId": "cf015825-98db-4e57-b9d1-9611ac0be074"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "text = text[300000:800000]\n",
        "characters_list = sorted(set(text))\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters_list))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters_list))\n",
        "seQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "sentences = []\n",
        "next_characters = []\n",
        "for i in range(0, len(text) - 40, 3):\n",
        "    sentences.append(text[i: i + 40])\n",
        "    next_characters.append(text[i + 40])\n",
        "x = np.zeros((len(sentences), seQ_LENGTH, len(characters_list)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(characters_list)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):\n",
        "        x[i, t, char_to_index[character]] = 1\n",
        "    y[i, char_to_index[next_characters[i]]] = 1\n"
      ],
      "metadata": {
        "id": "r_-KxfcFNSnx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(seQ_LENGTH, len(characters_list))))\n",
        "model.add(Dense(len(characters_list)))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "MruERGwGNbgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d342d74-bc3d-4b80-c43a-d0871de4b268"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop\n",
        "model.compile(loss='categorical_crossentropy', optimizer = RMSprop(learning_rate=0.01))\n"
      ],
      "metadata": {
        "id": "hkgWZ-MjkdzI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXrc1TwNlHaU",
        "outputId": "d81c3ed1-3cd2-43c1-e5d5-8f134f01d8e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 154ms/step - loss: 2.5130\n",
            "Epoch 2/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 149ms/step - loss: 1.7630\n",
            "Epoch 3/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 154ms/step - loss: 1.6015\n",
            "Epoch 4/4\n",
            "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 163ms/step - loss: 1.5255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b4230f38cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('textgenerator.keras')"
      ],
      "metadata": {
        "id": "xkexw4OxlRkp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "vcUxJYYnlXoB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "  start_index = random.randint(0, len(text) - seQ_LENGTH - 1)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + seQ_LENGTH]\n",
        "  generated = sentence\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1, seQ_LENGTH, len(characters_list)))\n",
        "    for t, character in enumerate(sentence):\n",
        "        x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "    predictions = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(predictions, 0.1)\n",
        "    next_character = index_to_char[next_index]\n",
        "\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character\n",
        "\n",
        "\n",
        "  return generated\n",
        "\n",
        "print('--------0.2--------')\n",
        "print(generate_text(300, 0.2))\n",
        "print('--------0.4--------')\n",
        "print(generate_text(300, 0.4))\n",
        "print('--------0.6--------')\n",
        "print(generate_text(300, 0.6))\n",
        "print('--------0.8--------')\n",
        "print(generate_text(300, 0.8))\n",
        "print('--------1.0--------')\n",
        "print(generate_text(300, 1.0))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1UCXxvvnzhq",
        "outputId": "904305e1-fe6d-4096-bd93-fcda2c29fb4c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------0.2--------\n",
            " good counsel may the cause remove.\n",
            "\n",
            "benvolio:\n",
            "who is the brother of the brother of the seace,\n",
            "and thou shall be the words the breath, thoughts the words,\n",
            "and thou see the sear the sear the from the seace\n",
            "that shall the words the words and make thee in the brother,\n",
            "and i wast the words the brother of the crown,\n",
            "and thou not the brother of\n",
            "--------0.4--------\n",
            "\n",
            "\n",
            "florizel:\n",
            "old sir, i know\n",
            "she prizes not the words the brother of the crown,\n",
            "and i wast thou see the words the words to the seack\n",
            "the sear the from the seach of the brother,\n",
            "and i wast thou see the sear the seace and thoughts,\n",
            "and i wast thou see the words the seace of the brother,\n",
            "and i wast thou wearing heart with his forth,\n",
            "and i was\n",
            "--------0.6--------\n",
            "ear me with patience but to speak a words,\n",
            "and i wast thou see the words of the words,\n",
            "and thou shall stay the sear the from the seace,\n",
            "and i wast thou see the words the words the words,\n",
            "and i wast thou wearing hand to the from the seace,\n",
            "and thou sees the sear the from the sear\n",
            "thou wearing heart the words the words and marrial,\n",
            "the word\n",
            "--------0.8--------\n",
            "but that his negligence, his folly, fear\n",
            "the sear the seach of the words the words,\n",
            "and well the words the words the words the words,\n",
            "and i wast thou hast the words the words,\n",
            "and i wast thou see the words the brother,\n",
            "and who was the sear the for the for the seace,\n",
            "and i wast i am so the forth the sear\n",
            "the proverel of the words the words\n",
            "--------1.0--------\n",
            "is apparel.\n",
            "\n",
            "clown:\n",
            "not a more cowardly sould the words the seace,\n",
            "and i wast i am so the brother of the brother,\n",
            "and i wast thou see the words the words the brother,\n",
            "and well the words the words of the sear\n",
            "the sear the sear the sear the sear the from the words,\n",
            "and i was the seace the brother of the seack\n",
            "the sear the properse the words\n"
          ]
        }
      ]
    }
  ]
}