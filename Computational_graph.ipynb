{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX/aUDxs34Uxw05/YsUY4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janjon39/Generate-Poetic-Texts/blob/main/Computational_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the Neural Network as a class\n",
        "class ComputationalGraphNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Define layers manually\n",
        "        self.layer1_w = nn.Parameter(torch.tensor([0.5, -1.2, 0.7]))\n",
        "        self.layer1_b = nn.Parameter(torch.tensor([0.1, 0.0, -0.3]))\n",
        "\n",
        "        self.layer2_w = nn.Parameter(torch.tensor([1.0, -0.5]))\n",
        "        self.layer2_b = nn.Parameter(torch.tensor([0.2, 0.3]))\n",
        "\n",
        "        self.output_w = nn.Parameter(torch.tensor(0.9))\n",
        "        self.output_b = nn.Parameter(torch.tensor(-0.1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Input: {x.item()}\\n\")\n",
        "\n",
        "        # ----- Layer 1 -----\n",
        "        z1 = self.layer1_w * x + self.layer1_b\n",
        "        a1 = F.relu(z1)\n",
        "        print(\"Layer 1 (ReLU):\", a1.tolist())\n",
        "\n",
        "        # ----- Layer 2 -----\n",
        "        z2 = self.layer2_w * x + self.layer2_b\n",
        "        a2 = torch.sigmoid(z2)\n",
        "        print(\"Layer 2 (Sigmoid):\", a2.tolist())\n",
        "\n",
        "        # ----- Combine and apply Tanh -----\n",
        "        combined = torch.sum(a1) + torch.sum(a2)\n",
        "        c = torch.tanh(combined)\n",
        "        print(f\"Combined (Tanh): {c.item()}\")\n",
        "\n",
        "        # ----- Output (Linear) -----\n",
        "        output = self.output_w * c + self.output_b\n",
        "        print(f\"Output (Linear): {output.item()}\")\n",
        "        return output\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# (Forward + Backward)\n",
        "\n",
        "# Create input tensor\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Create model instance\n",
        "model = ComputationalGraphNN()\n",
        "\n",
        "# Forward pass\n",
        "output = model(x)\n",
        "\n",
        "# Backward pass (compute gradients)\n",
        "output.backward()\n",
        "\n",
        "# Print gradient of output w.r.t. input\n",
        "print(\"\\n=== Gradients ===\")\n",
        "print(f\"d(output)/d(x): {x.grad.item()}\")\n",
        "\n",
        "# Show some parameter gradients\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}.grad = {param.grad}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHFWcVQ-_3DN",
        "outputId": "7e45a9f6-94ae-430d-b65f-c03b4d4fc308"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 2.0\n",
            "\n",
            "Layer 1 (ReLU): [1.100000023841858, 0.0, 1.0999999046325684]\n",
            "Layer 2 (Sigmoid): [0.9002495408058167, 0.3318122327327728]\n",
            "Combined (Tanh): 0.9979130029678345\n",
            "Output (Linear): 0.7981216311454773\n",
            "\n",
            "=== Gradients ===\n",
            "d(output)/d(x): 0.004424192942678928\n",
            "layer1_w.grad = tensor([0.0075, 0.0000, 0.0075])\n",
            "layer1_b.grad = tensor([0.0038, 0.0000, 0.0038])\n",
            "layer2_w.grad = tensor([0.0007, 0.0017])\n",
            "layer2_b.grad = tensor([0.0003, 0.0008])\n",
            "output_w.grad = 0.9979130029678345\n",
            "output_b.grad = 1.0\n"
          ]
        }
      ]
    }
  ]
}